<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Vaden Masrani | publications</title>
<meta name="description" content="Vaden Masrani's academic website. A place to link to news, recent work, and what's been interesting me of late.
">

<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/css/mdb.min.css" integrity="sha256-/SwJ2GDcEt5382i8zqDwl36VJGECxEoIcBIuoLmLR4g=" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css"  integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- Open Graph -->


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm fixed-top">
    <div class="container">
      
      
      
      
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Vaden</span>   Masrani
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/random/">
                random
                
              </a>
          </li>
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description">publications in reversed chronological order</p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICML</abbr>
    
  
  </div>

  <div id="brekelmans2020exponential" class="col-sm-8">
    
      <span class="title">All in the Exponential Family: Bregman Duality in Thermodynamic Variational Inference</span>
      <span class="author">
        
          
            
              
                
                  Brekelmans, Rob,
                
              
            
          
        
          
            
              
                <em>Masrani, Vaden</em>,
              
            
          
        
          
            
              
                
                  Wood, Frank,
                
              
            
          
        
          
            
              
                
                  Ver Steeg, Greg,
                
              
            
          
        
          
            
              
                
                  and Galstyan, Aram and
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>International Conference On Machine Learning</em>
      
      
        2020
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
      [<a href="http://arxiv.org/abs/2007.00642" target="_blank">arXiv</a>]
    
    
    
    
    
    
    
      [<a href="https://github.com/vmasrani/tvo_all_in" target="_blank">Code</a>]
    
    

    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p> The recently proposed Thermodynamic Variational Objective (TVO) leverages thermodynamic integration to provide a family of variational inference objectives, which both tighten and generalize the ubiquitous Evidence Lower Bound (ELBO). However, the tightness of TVO bounds was not previously known, an expensive grid search was used to choose a "schedule" of intermediate distributions, and model learning suffered with ostensibly tighter bounds. In this work, we propose an exponential family interpretation of the geometric mixture curve underlying the TVO and various path sampling methods, which allows us to characterize the gap in TVO likelihood bounds as a sum of KL divergences. We propose to choose intermediate distributions using equal spacing in the moment parameters of our exponential family, which matches grid search performance and allows the schedule to adaptively update over the course of training. Finally, we derive a doubly reparameterized gradient estimator which improves model learning and allows the TVO to benefit from more refined bounds. To further contextualize our contributions, we provide a unified framework for understanding thermodynamic integration and the TVO using Taylor series remainders.</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="wood2020planning" class="col-sm-8">
    
      <span class="title">Planning as Inference in Epidemiological Models</span>
      <span class="author">
        
          
            
              
                
                  Wood, Frank,
                
              
            
          
        
          
            
              
                
                  Warrington, Andrew,
                
              
            
          
        
          
            
              
                
                  Naderiparizi, Saeid,
                
              
            
          
        
          
            
              
                
                  Weilbach, Christian,
                
              
            
          
        
          
            
              
                <em>Masrani, Vaden</em>,
              
            
          
        
          
            
              
                
                  Harvey, William,
                
              
            
          
        
          
            
              
                
                  Scibior, Adam,
                
              
            
          
        
          
            
              
                
                  Beronov, Boyan,
                
              
            
          
        
          
            
              
                
                  and Nasseri, Ali
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>arXiv preprint</em>
      
      
        2020
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
      [<a href="http://arxiv.org/abs/2003.13221" target="_blank">arXiv</a>]
    
    
    
    
    
    
    
      [<a href="https://github.com/plai-group/covid" target="_blank">Code</a>]
    
    

    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>In this work we demonstrate how existing software tools can be used to automate parts  of infectious disease-control policy-making via performing inference in existing epidemiological  dynamics models. The kind of inference tasks undertaken include computing, for planning purposes, the posterior distribution over putatively controllable, via direct policy-making choices,  simulation model parameters that give rise to acceptable disease progression outcomes. Neither the full capabilities of such inference automation software tools nor their utility for planning is widely disseminated at the current time. Timely gains in understanding about these tools and how they can be used may lead to more fine-grained and less economically damaging policy  prescriptions, particularly during the current COVID-19 pandemic.</p>
    </span>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CVPR</abbr>
    
  
  </div>

  <div id="bateni2019improved" class="col-sm-8">
    
      <span class="title">Improved Few-Shot Visual Classification</span>
      <span class="author">
        
          
            
              
                
                  Bateni, Peyman,
                
              
            
          
        
          
            
              
                
                  Goyal, Raghav,
                
              
            
          
        
          
            
              
                <em>Masrani, Vaden</em>,
              
            
          
        
          
            
              
                
                  Wood, Frank,
                
              
            
          
        
          
            
              
                
                  and Sigal, Leonid
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>Conference on Computer Vision and Pattern Recognition</em>
      
      
        2019
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
      [<a href="http://arxiv.org/abs/1912.03432" target="_blank">arXiv</a>]
    
    
    
    
    
    
    
      [<a href="https://github.com/peymanbateni/simple-cnaps" target="_blank">Code</a>]
    
    

    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Few-shot learning is a fundamental task in computer vision that carries the promise of
  alleviating the need for exhaustively labeled data. Most few-shot learning approaches to date have focused on progressively more complex neural feature extractors and classifier adaptation strategies, as well as the refinement of the task definition itself. In this paper, we explore the hypothesis that a simple class-covariance-based distance metric, namely the Mahalanobis distance, adopted into a state of the art few-shot learning approach (CNAPS) can, in and of itself, lead to a significant performance improvement. We also discover that it is possible to learn adaptive feature extractors that allow useful estimation of the high dimensional feature covariances required by this metric from surprisingly few samples. The result of our work is a new "Simple CNAPS" architecture which has up to 9.2% fewer trainable parameters than CNAPS and performs up to 6.1% better than state of the art on the standard few-shot image classification benchmark dataset.</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="masrani2019thermodynamic" class="col-sm-8">
    
      <span class="title">The Thermodynamic Variational Objective</span>
      <span class="author">
        
          
            
              
                <em>Masrani, Vaden</em>,
              
            
          
        
          
            
              
                
                  Le, Tuan Anh,
                
              
            
          
        
          
            
              
                
                  and Wood, Frank
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>Neural Information Processing Systems</em>
      
      
        2019
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
      [<a href="http://arxiv.org/abs/1907.00031" target="_blank">arXiv</a>]
    
    
    
    
    
      [<a href="/assets/pdf/neurips_tvo_poster.pdf" target="_blank">Poster</a>]
    
    
    
      [<a href="https://github.com/vmasrani/tvo" target="_blank">Code</a>]
    
    

    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>We introduce the thermodynamic variational objective (TVO) for learning in both continuous and discrete deep generative models. The TVO arises from a key connection between variational inference and thermodynamic integration that results in a tighter lower bound to the log marginal likelihood than the standard variational variational evidence lower bound (ELBO) while remaining as broadly applicable. We provide a computationally efficient gradient estimator for the TVO that applies to continuous, discrete, and non-reparameterizable distributions and show that the objective functions used in variational inference, variational autoencoders, wake sleep, and inference compilation are all special cases of the TVO. We use the TVO to learn both discrete and continuous deep generative models and empirically demonstrate state of the art model and inference network learning.</p>
    </span>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="masrani2018detecting" class="col-sm-8">
    
      <span class="title">Detecting dementia from written and spoken language</span>
      <span class="author">
        
          
            
              <em>Masrani, Vaden</em>
            
          
        
      </span>

      <span class="periodical">
      
      
        2018
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
      [<a href="https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0362923" target="_blank">HTML</a>]
    
    
    
    
    
    
      [<a href="https://github.com/vmasrani/dementia_classifier" target="_blank">Code</a>]
    
    
      [<a href="https://github.com/vadmas/blog_corpus" target="_blank">Dataset</a>]
    

    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>This thesis makes three main contributions to existing work on the automatic detection of dementia from language. First we introduce a new set of biologically motivated spatial neglect features, and show their inclusion achieves a new state of the art in classifying Alzheimer’s disease (AD) from recordings of patients undergoing the Boston Diagnostic Aphasia Examination. Second we demonstrate how a simple domain adaptation algorithm can be used to leveraging AD data to improve classification of mild cognitive impairment (MCI), a condition characterized by a slight-but-noticeable decline in cognition that does not meet the criteria for dementia, and a condition for which reliable data is scarce. Third, we investigate whether dementia can be detected from written rather than spoken language, and show a range of classifiers achieve a performance far above baseline. Additionally, we create a new corpus of blog posts written by authors with and without dementia and make it publicly available for future researchers.</p>
    </span>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="masrani2017domain" class="col-sm-8">
    
      <span class="title">Domain adaptation for detecting mild cognitive impairment</span>
      <span class="author">
        
          
            
              
                <em>Masrani, Vaden</em>,
              
            
          
        
          
            
              
                
                  Murray, Gabriel,
                
              
            
          
        
          
            
              
                
                  Field, Thalia Shoshana,
                
              
            
          
        
          
            
              
                
                  and Carenini, Giuseppe
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In Canadian Conference on Artificial Intelligence</em>
      
      
        2017
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
      [<a href="https://link.springer.com/chapter/10.1007%2F978-3-319-57351-9_29" target="_blank">HTML</a>]
    
    
    
    
    
    
      [<a href="https://github.com/vmasrani/dementia_classifier" target="_blank">Code</a>]
    
    

    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Lexical and acoustic markers in spoken language can be used to detect mild cognitive impairment (MCI), a condition which is often a precursor to dementia and frequently causes some degree of dysphasia. Research to develop such a diagnostic tool for clinicians has been hindered by the scarcity of available data. This work uses domain adaptation to adapt Alzheimer’s data to improve classification accuracy of MCI. We evaluate two simple domain adaptation algorithms, AUGMENT and CORAL, and show that AUGMENT improves upon all baselines. Additionally we investigate the use of previously unconsidered discourse features and show they are not useful in distinguishing MCI from healthy controls.</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="masrani2017detecting" class="col-sm-8">
    
      <span class="title">Detecting dementia through retrospective analysis of routine blog posts by bloggers with dementia</span>
      <span class="author">
        
          
            
              
                <em>Masrani, Vaden</em>,
              
            
          
        
          
            
              
                
                  Murray, Gabriel,
                
              
            
          
        
          
            
              
                
                  Field, Thalia,
                
              
            
          
        
          
            
              
                
                  and Carenini, Giuseppe
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In BioNLP 2017</em>
      
      
        2017
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
      [<a href="http://aclweb.org/anthology/W17-2329" target="_blank">HTML</a>]
    
    
    
    
    
    
      [<a href="https://github.com/vmasrani/dementia_classifier" target="_blank">Code</a>]
    
    
      [<a href="https://github.com/vadmas/blog_corpus" target="_blank">Dataset</a>]
    

    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>We investigate if writers with dementia can be automatically distinguished from those without by analyzing linguistic markers in written text, in the form of blog posts. We have built a corpus of several thousand blog posts, some by people with dementia and others by people with loved ones with dementia. We use this dataset to train and test several machine learning methods, and achieve prediction performance at a level far above the baseline.</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="johnson2017generating" class="col-sm-8">
    
      <span class="title">Generating and Evaluating Summaries for Partial Email Threads: Conversational Bayesian Surprise and Silver Standards</span>
      <span class="author">
        
          
            
              
                
                  Johnson, Jordon,
                
              
            
          
        
          
            
              
                <em>Masrani, Vaden</em>,
              
            
          
        
          
            
              
                
                  Carenini, Giuseppe,
                
              
            
          
        
          
            
              
                
                  and Ng, Raymond
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</em>
      
      
        2017
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
      [<a href="http://www.sigdial.org/workshops/conference18/proceedings/pdf/SIGDIAL32.pdf" target="_blank">HTML</a>]
    
    
    
    
    
    
    

    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>We define and motivate the problem of summarizing partial email threads. This problem introduces the challenge of generating reference summaries for partial threads when human annotation is only available for the threads as a whole, particularly when the human-selected sentences are not uniformly distributed within the threads. We propose an oracular algorithm for generating these reference summaries with arbitrary length, and we are making the resulting dataset publicly available. In addition, we apply a recent unsupervised method based on Bayesian Surprise that incorporates background knowledge into partial thread summarization, extend it with conversational features, and modify the mechanism by which it handles redundancy.</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="palyart2017study" class="col-sm-8">
    
      <span class="title">A study of social interactions in open source component use</span>
      <span class="author">
        
          
            
              
                
                  Palyart, Marc,
                
              
            
          
        
          
            
              
                
                  Murphy, Gail C,
                
              
            
          
        
          
            
              
                and <em>Masrani, Vaden</em>
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>IEEE Transactions on Software Engineering</em>
      
      
        2017
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
      [<a href="http://ieeexplore.ieee.org/abstract/document/8049385/" target="_blank">HTML</a>]
    
    
    
    
    
    
    

    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>All kinds of software projects, whether open or closed source, rely on open source components. Repositories that serve open source components to organizations, such as the Central Repository and npmjs.org, report billions of requests per year. Despite the widespread reliance of projects on open source components, little is known about the social interactions that occur between developers of a project using a component and developers of the component itself. In this paper, we investigate the social interactions that occur for 5,133 pairs of projects, from two different communities (Java and Ruby) representing user projects that depend on a component project. We consider such questions as how often are there social interactions when a component is used? When do the social interactions occur? And, why do social interactions occur? Our results provide insight into how socio-technical interactions occur beyond the level of an individual or small group of projects previously studied by others and identify the need for a new model of socio-technical congruence for dependencies between, instead of within, projects.</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="field2017improving" class="col-sm-8">
    
      <span class="title">Improving Diagnostic Accuracy Of Alzheimer’s Disease From Speech Analysis Using Markers Of Hemispatial Neglect</span>
      <span class="author">
        
          
            
              
                
                  Field, Thalia S,
                
              
            
          
        
          
            
              
                <em>Masrani, Vaden</em>,
              
            
          
        
          
            
              
                
                  Murray, Gabriel,
                
              
            
          
        
          
            
              
                
                  and Carenini, Giuseppe
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>Alzheimer’s &amp; Dementia: The Journal of the Alzheimer’s Association</em>
      
      
        2017
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
    
      [<a href="http://www.alzheimersanddementia.com/article/S1552-5260(17)32851-0/abstract" target="_blank">HTML</a>]
    
    
    
    
    
    
      [<a href="https://github.com/vmasrani/dementia_classifier" target="_blank">Code</a>]
    
    

    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Machine learning has been previously used to distinguish patients with Alzheimer’s disease (AD) versus healthy controls using transcripts of descriptions of the “Cookie Theft” picture from the Boston Diagnostic Aphasia Exam. Previous work achieved a positive predictive value (PPV) of 0.83 (95% CI 0.79 – 0.87) and negative predictive value (NPV) of 0.81 (0.74 – 0.88) using lexical (e.g. word choice and complexity) and acoustic (e.g. pauses, prosody) features extracted from interviews. Given that language deficits may be associated with other dominant hemisphere findings, we evaluated the diagnostic utility in adding markers of hemispatial neglect to our previous baseline algorithm.</p>
    </span>
    
  </div>
</div>
</li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2020 Vaden Masrani.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    Last updated: August 08, 2020.
    
  </div>
</footer>



  </body>

  <!-- Load Core and Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.0/umd/popper.min.js" integrity="sha256-OH05DFHUWzr725HmuHo3pnuvUUn+TJuj8/Qz9xytFEw=" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/js/mdb.min.js"  integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />


<!-- Load KaTeX -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" integrity="sha256-V8SV2MO1FUb63Bwht5Wx9x6PVHNa02gv8BgH/uH3ung=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js" integrity="sha256-F/Xda58SPdcUCr+xhSGz9MA2zQBPb0ASEYKohl8UCHc=" crossorigin="anonymous"></script>
<script src="/assets/js/katex.js"></script>



<!-- Load Mansory & imagesLoaded -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="" crossorigin="anonymous"></script>
<script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>

<!-- Project Cards Layout -->
<script type="text/javascript">
  // Init Masonry
  var $grid = $('.grid').masonry({
    gutter: 10,
    horizontalOrder: true,
    itemSelector: '.grid-item',
  });
  // layout Masonry after each image loads
  $grid.imagesLoaded().progress( function() {
    $grid.masonry('layout');
  });
</script>







</html>
